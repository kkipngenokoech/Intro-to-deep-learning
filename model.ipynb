{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30804,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MODEL","metadata":{}},{"cell_type":"markdown","source":"This is a neural network that is defined using the `torch.nn.module` class. It consists of layers and forward computation logic.","metadata":{}},{"cell_type":"markdown","source":"## DEFINING A NEURAL NETWORK\n\nA neural network can be defined in several ways:\n\n1. creating a sequence of layers: `nn.Sequential`\n2. using `nn.Module`.\n3. hybrid of `nn.Module` and `nn.Sequential`\n4. Using pre-defined models (transfer learning)\n","metadata":{}},{"cell_type":"markdown","source":"### nn.Sequential\n\nIt stacks layers sequentially. Each layer is executed in order as it is defined. ","metadata":{}},{"cell_type":"code","source":"import torch.nn as nn\nmodel = nn.Sequential(\n    nn.Linear(2, 4),\n    nn.ReLU(),\n    nn.Linear(4,8)\n)\nmodel","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T07:49:33.944908Z","iopub.execute_input":"2024-12-21T07:49:33.945328Z","iopub.status.idle":"2024-12-21T07:49:33.956379Z","shell.execute_reply.started":"2024-12-21T07:49:33.945292Z","shell.execute_reply":"2024-12-21T07:49:33.955017Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"Sequential(\n  (0): Linear(in_features=2, out_features=4, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=4, out_features=8, bias=True)\n)"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"### nn.Module\n\nThis is the base class for all neural networks.","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\n\nclass BasicNeuralNetwork(nn.Module):\n    def __init__(self, input, output):\n        super(BasicNeuralNetwork, self).__init__()\n        # Define custom layers\n        self.fc1 = nn.Linear(input, 128)  # First layer\n        self.fc2 = nn.Linear(128, 64)    # Second layer\n        self.fc3 = nn.Linear(64, output) # Output layer\n\n    def forward(self, x):\n        # Apply activations\n        x = torch.relu(self.fc1(x))  # Apply ReLU to the first layer\n        x = torch.relu(self.fc2(x))  # Apply ReLU to the second layer\n        output = self.fc3(x)         # Linear activation for the output layer\n        return output\n\n# Define the model\nmodel = BasicNeuralNetwork(input=784, output=10)\n\n# Print the model\nprint(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-21T07:48:58.245218Z","iopub.execute_input":"2024-12-21T07:48:58.245623Z","iopub.status.idle":"2024-12-21T07:48:58.255408Z","shell.execute_reply.started":"2024-12-21T07:48:58.245587Z","shell.execute_reply":"2024-12-21T07:48:58.254183Z"}},"outputs":[{"name":"stdout","text":"BasicNeuralNetwork(\n  (fc1): Linear(in_features=784, out_features=128, bias=True)\n  (fc2): Linear(in_features=128, out_features=64, bias=True)\n  (fc3): Linear(in_features=64, out_features=10, bias=True)\n)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## MODEL METHODS\n\n`torch.nn.Module` has alot of builtin methods:\n\n1. ____init____\n2. forward\n3. eval()\n4. train()\n5. state_dict()\n6. load_state_dict()\n7. parameters()\n8. zero_grad()\n9. to()\n10. cuda(), cpu()","metadata":{}},{"cell_type":"markdown","source":"### __init__\n\nHere is where we define the architecture of a neural network. it is used to initialize the layers used for our architecture. Any nn.Module or nn.Parameter defined in the __init__ method is registered as a model parameter and will appear in the `model.parameters()`.\n\n```python\nclass BasicNeuralNetwork(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size):\n        super(BasicNeuralNetwork, self).__init__()\n        # define the other layers here\n\n```\n`super()` allows us to first inherit from the nn.Module base class","metadata":{}},{"cell_type":"markdown","source":"### forward\n\nThis method defines the forward pass of a neural network. it is basically the learning pipeline, give me an input I pass it through some pipeline and I will give you my predicted output.\n\nyou don't always get to call the `forward method` explicility, you just use our model name and pass your inputs, it will return the outputs. This is what I mean:\n```python\nclass BasicNeuralNetwork(nn.Module):\n    def __init__(self, input, hidden, output):\n        super(BasicNeuralNetwork, self).__init__()\n        # layers\n        self.fc1 = nn.Linear(input, hidden)\n        self.relu = nn.Relu()\n        self.fc2 = nn.Linear(hidden, output)\n    def forward(self, x):\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        return x\nbasicNeuralNetwork = BasicNeuralNetwork(input=256, hidden= 512, output = 2048)\noutputs = basicNeuralNetwork(inputs)\n```\n\n__NOTE__: Layers are not defined in the `forward method`. They are defined in the `__init__` method","metadata":{}},{"cell_type":"markdown","source":"### eval\n\nThis is used to set the model to evaluation mode. This disables layers like `dropout` and `Batchnorm` hence making the system to be determinstic.\n\n```python\nbasicNeuralNetwork.eval()\n```","metadata":{}},{"cell_type":"markdown","source":"### train\n\nThis is used to set the model into training mode. This activates layers like `Dropout` and `Batchnorm`.\n\n```python\nbasicNeuralNetwork.train()\n```","metadata":{}},{"cell_type":"markdown","source":"### state_dict() & load_state_dict()\n\nThis is a python dictionary object that maps each layer to its parameter tensor. it contains the parameters of a model e.g `weights & biases`, and the buffers: running stats in batch normalization layers.\n\nThis is crucial for saving and loading models in pytorch:\n```python\ntorch.save(basicNeuralNetwork.state_dict(), 'basicNeuralNetwork.pth')\n```\n\n`basicNeuralNetwork.state_dict()` returns the model's learned weights and buffers and stores it in `basicNeuralNetwork.pth` file.\n\nTo load the model, we need to first create a new instance of our model class, (or override the one we have already). What to note though is that the model architecture needs to match the one we used while saving the `state_dict`:\n\n```python\nnewBasicInstanceNeuralNetwork = BasicNeuralNetwork(input=256, hidden=512, output=2048)\nnewBasicInstanceNeuralNetwork.load_state_dict(torch.load('basicNeuralNetwork.pth')\n```\n\nYou can also use this to save and load the opitmizer states by replacing the `model` with `optimizer`\n\n__N/B:__ `torch.save(model.state_dict(), 'name.pth')` saves only parameters and allows portability across pytorch versions while `torch.save(model, 'name.pth')` saves the arch + the parameters but is not portable across various pytorch versions.","metadata":{}},{"cell_type":"markdown","source":"### parameters()\n\nThis is used to access parameters (weights and biases), of a model. it returns an iterator which you can loop through to access individual parameters or convert it into a list.\n\n```python\nfor param in basicNeuralNetwork.parameters():\n    print(param)\n```\n\nThis will loop through all weights and biases and print them out.\n\n#### use cases of parameters()\n1. passing them to optimizers for updates: `optimizer = nn.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.9)`\n2. Freezing layers to prevent them from updating during training, by setting `requires_grad` to `False`\n```python\nfor params in model.fc1.parameters():\n    params.requires_grad = False # it freezes the params of the first layer fc1\n```\n3. Manually inspecting and updating paramters\n```python\nfor param in model.fc2.parameters():\n    param.grad = None #zeroing gradients\n```","metadata":{}},{"cell_type":"markdown","source":"### is_cuda\n\nA boolean that tells you if the model is currently on a GPU\n\n```python\nif model.is_cuda:\n    print('model is on GPU')\n```","metadata":{}},{"cell_type":"markdown","source":"### to\n\nThis is used to move the model to different devices \n```python\nmodel.to('cuda')\nmodel.to(device)\n```\n\nalt you can:\n```python\nmodel.cuda()\nmodel.cpu()\n```","metadata":{}}]}